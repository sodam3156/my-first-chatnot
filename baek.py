import streamlit as st
import google.generativeai as genai

# Streamlit secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except (KeyError, FileNotFoundError):
    st.error("ğŸš¨ Gemini API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .streamlit/secrets.tomlì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()

# ëª¨ë¸ ì„¤ì •
model = genai.GenerativeModel('gemini-2.5-flash')

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Gemini ì±—ë´‡ ğŸ¤–",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("Gemini 2.5 Flash ì±—ë´‡ ğŸ¤–")
st.caption("Streamlitê³¼ Gemini APIë¥¼ ì´ìš©í•œ ì±—ë´‡ì…ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ(session_state) ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì±—ë´‡ ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # ì´ì „ ëŒ€í™”ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë¸ì— ì „ë‹¬
        chat_session = model.start_chat(
            history=[
                {"role": message["role"], "parts": [message["content"]]}
                for message in st.session_state.messages[:-1] # ë§ˆì§€ë§‰ ì‚¬ìš©ì ì…ë ¥ì€ ì œì™¸
            ]
        )
        
        try:
            response = chat_session.send_message(prompt, stream=True)
            for chunk in response:
                full_response += chunk.text
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            full_response = "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            message_placeholder.markdown(full_response)
    
    # ì±—ë´‡ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": full_response})